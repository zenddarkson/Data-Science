# -*- coding: utf-8 -*-
"""Examen2_1MTR19_20196355.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_rLP3mOz47ciSat_gSIb93AZWfOmjvMx

#Nombre: Armando Arturo Custodio Díaz
#Código: 20196355
"""

# Importando librerias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive
from scipy.fft import fft, ifft
import seaborn as sns

# Conectando google drive con google colab
drive.mount('/content/drive')

"""#EDA & Preprocesamiento de datos

1. Lectura de Datos:
"""

# Specify the file path
file_path = '/content/drive/MyDrive/TemasH/Lab06/train_FD001.txt'

# Define column names
columns = ['unit_number', 'cycles'] + [f'operational_settings_{i}' for i in range(1, 4)] + \
          [f'sensor_{i}' for i in range(1, 22)]

# Read data from the file into a pandas DataFrame
train_FD001 = pd.read_csv(file_path, delim_whitespace=True, header=None, names=columns)

# Display the DataFrame
train_FD001.head()

"""Se tiene la función "plot_sensor_data_for_unit" para poder graficar la data de todos los sensores para un valor determinado de "unit_number". Se tendrán unos cuantos ejemplos para obtener una primera impresión de los datos de los sensores"""

def plot_sensor_data_for_unit(df, unit_number):
    # Set up the plot layout
    num_rows = 3
    num_cols = 7

    # Create subplots
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 8))
    fig.suptitle(f'Sensor Data vs. Cycles for Unit {unit_number}', fontsize=16)

    # Loop through sensors and plot data
    for sensor_num in range(1, 22):
        row_idx = (sensor_num - 1) // num_cols
        col_idx = (sensor_num - 1) % num_cols

        # Select data for the current sensor and unit_number
        sensor_cols = [f'sensor_{sensor_num}', 'cycles']
        sensor_data = df[(df['unit_number'] == unit_number)][sensor_cols]

        # Plot data for the given unit_number
        axes[row_idx, col_idx].plot(sensor_data['cycles'], sensor_data[f'sensor_{sensor_num}'])

        # Set subplot title
        axes[row_idx, col_idx].set_title(f'Sensor {sensor_num}')

        # Set common labels
        if col_idx == 0:
            axes[row_idx, col_idx].set_ylabel('Sensor Values')

        if row_idx == num_rows - 1:
            axes[row_idx, col_idx].set_xlabel('Cycles')

    # Adjust layout
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # Show the plot
    plt.show()

# Para valores individuales de unit_number, se muestra la data obtenida del sensor 5
plot_sensor_data_for_unit(train_FD001, unit_number=5)

# Para valores individuales de unit_number, se muestra la data obtenida del sensor 1
plot_sensor_data_for_unit(train_FD001, unit_number=1)

# Para valores individuales de unit_number, se muestra la data obtenida del sensor 99
plot_sensor_data_for_unit(train_FD001, unit_number=99)

"""Se observa una tendencia para los sensores 1, 5, 10, 16, 18 y 19. Para asegurar que esto se de para los 100 casos, se graficarán todos los datos de los sensores juntos, para confirmar si esta tendencia se da para los 100 unit_number y así poder tratar estos datos."""

def plot_sensor_data(df,num_rows,num_cols):

    # Create subplots
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))
    fig.suptitle('Sensor Data vs. Cycles by Unit Number', fontsize=16)

    # Loop through sensors and plot data
    for sensor_num in range(1, num_rows*num_cols+1):
        row_idx = (sensor_num - 1) // num_cols
        col_idx = (sensor_num - 1) % num_cols

        # Select data for the current sensor
        sensor_cols = [f'sensor_{sensor_num}', 'cycles', 'unit_number']
        sensor_data = df[sensor_cols]

        # Plot each unit_number in a different color
        for unit_number, data in sensor_data.groupby('unit_number'):
            axes[row_idx, col_idx].plot(data['cycles'], data[f'sensor_{sensor_num}'])

        # Set subplot title
        axes[row_idx, col_idx].set_title(f'Sensor {sensor_num}')

        # Set common labels
        if col_idx == 0:
            axes[row_idx, col_idx].set_ylabel('Sensor Values')

        if row_idx == num_rows - 1:
            axes[row_idx, col_idx].set_xlabel('Cycles')

    # Adjust layout
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # Show the plot
    plt.show()

# Data de todos los sensores
plot_sensor_data(train_FD001,3,7)

"""Ahora, tenemos que eliminar las columnas de los sensores:


*   Sensor 1
*   Sensor 5
*   Sensor 10
*   Sensor 16
*   Sensor 18
*   Sensor 19

Para el sensor 6, se guardarán dos datos distintos, para posteriormente evaluar
si conviene eliminarlo o no al evaluar el RMSE para dos casos, cuando se elimina la data del sensor 6 y cuando no


"""

# Drop specified columns from a copy of the original DataFrame
columns_to_drop = ['sensor_1', 'sensor_5', 'sensor_10', 'sensor_16', 'sensor_18', 'sensor_19']
modified_train = train_FD001.drop(columns=columns_to_drop).copy()

# Rename the remaining columns sequentially
remaining_columns = [f'sensor_{i}' for i in range(1, 22 - len(columns_to_drop))]
modified_train.columns = ['unit_number', 'cycles'] + [f'operational_settings_{i}' for i in range(1, 4)] + remaining_columns

# Now modified_train_FD001 has the desired columns
display(modified_train.head())

# Drop specified columns from a copy of the original DataFrame
columns_to_drop = ['sensor_1', 'sensor_5', 'sensor_6', 'sensor_10', 'sensor_16', 'sensor_18', 'sensor_19']
modified_train_No_S6 = train_FD001.drop(columns=columns_to_drop).copy()

# Rename the remaining columns sequentially
remaining_columns = [f'sensor_{i}' for i in range(1, 22 - len(columns_to_drop))]
modified_train_No_S6.columns = ['unit_number', 'cycles'] + [f'operational_settings_{i}' for i in range(1, 4)] + remaining_columns

# Now modified_train_FD001 has the desired columns
display(modified_train_No_S6.head())

"""Se tiene lo siguiente:


*   modified_train : Data modificada, habiendo eliminado los datos de los sensores que no aportan, a excepción del sensor 6 que se pondrá a evaluación. Sensores 1, 5, 10, 16, 18, 19
*   modified_train_No_S6 : Data modificada, habiendo eliminado los datos de los sensores que no aportan. Sensores 1, 5, 10, 16, 18, 19 y 6

Se muestra los datos para 14 sensores, sin incluir Sensor_6 de la data original, sin embargo en todo momento, se tendrá en cuenta la data con y sin la inclusión de Sensor_6
"""

plot_sensor_data(modified_train_No_S6,2,7)

"""#Pre-Procesamiento de datos

Se tiene la tabla "missing_values_table" para evaluar el porcentaje de valores faltantes en la data procesada hasta ahora
"""

def missing_values_table(df):
        # Total missing values
        mis_val = df.isnull().sum()

        # Percentage of missing values
        mis_val_percent = 100 * df.isnull().sum() / len(df)

        # Make a table with the results
        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)

        # Rename the columns
        mis_val_table_ren_columns = mis_val_table.rename(
        columns = {0 : 'Missing Values', 1 : '% of Total Values'})

        # Sort the table by percentage of missing descending
        mis_val_table_ren_columns = mis_val_table_ren_columns[
            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(
        '% of Total Values', ascending=False).round(1)

        # Print some summary information
        print ("Your selected dataframe has " + str(df.shape[1]) + " columns.\n"
            "There are " + str(mis_val_table_ren_columns.shape[0]) +
              " columns that have missing values.")

        # Return the dataframe with missing information
        return mis_val_table_ren_columns

missing_values_table(modified_train)

missing_values_table(modified_train_No_S6)

"""Se tiene que la data procesada hasta ahora sin valores faltantes, a partir de ahora se realizará un análisis de outliers y con ello se procede a obtener gráficos para observar la data pre-procesada. Por lo tanto, dado a que no se encuentran valores faltantes, se hará un tratamiento de outliers"""

# Se define sigma_rule y sigma_rule_for_column para realizar el tratamiento de outliers

def sigma_rule(df, rule):
    # Find the last sensor column dynamically
    sensor_columns = [col for col in df.columns if col.startswith('sensor_')]
    last_sensor_column = max(sensor_columns, key=lambda x: int(x.split('_')[-1]))

    # Iterate through sensor columns and apply sigma rule
    for col in sensor_columns:
        if col <= last_sensor_column:
            df = sigma_rule_for_column(df, col, rule)

    # Drop rows with any NaN values after outlier removal
    df = df.dropna()

    return df

def sigma_rule_for_column(df, column, rule):
    # Copy the original column to avoid modifying the original data
    data = df[column].copy()

    # Calculating bounds for the specified sigma rule
    lower_bound = np.percentile(data, (100 - rule) / 2)
    upper_bound = np.percentile(data, 100 - (100 - rule) / 2)

    # Identifying outliers and dropping the entire row
    outliers_indices = data[(data < lower_bound) | (data > upper_bound)].index
    df = df.drop(outliers_indices)

    return df

# Tratamiento de Outliers, a diferentes valores de sigma

train_No_S6_Outliers99 = sigma_rule(modified_train_No_S6, rule=99.7)
train_No_S6_Outliers95 = sigma_rule(modified_train_No_S6, rule=95.8)
train_No_S6_Outliers68 = sigma_rule(modified_train_No_S6, rule=68.3)

train_Outliers99 = sigma_rule(modified_train, rule=99.7)
train_Outliers95 = sigma_rule(modified_train, rule=95.8)
train_Outliers68 = sigma_rule(modified_train, rule=68.3)

"""Ahora, se podrá observar como los outliers han sido eliminado y en la gráfica se puede observar los datos más concentrados. Además, se observará como los diferentes valores de la regla sigma cambia la concentración."""

plot_sensor_data(train_No_S6_Outliers99,2,7)

plot_sensor_data(train_No_S6_Outliers95,2,7)

plot_sensor_data(train_No_S6_Outliers68,2,7)

"""En este caso, es mejor quedarnos con train_No_S6_Outliers95 y train_Outliers95 para continuar con nuestro análisis. Por otro lado, ahora se analizará además, modified_train_No_S6 y modified_train. Es decir, tenemos 4 valores a los cuales someteremos a nuestro modelo de regresión

*   modified_train
*   modified_train_No_S6

*   train_Outliers99
*   train_No_S6_Outliers99

Se define la función para agregar el RUL, según la columna "cycles"
"""

def add_RUL_column(df):
    # Group by unit_number and find the maximum value of cycles in each subgroup
    max_cycles_per_unit = df.groupby('unit_number')['cycles'].max()

    # Map the max cycles values back to the original DataFrame
    df['max_cycles'] = df['unit_number'].map(max_cycles_per_unit)

    # Calculate RUL (Remaining Useful Life) for each row
    df['RUL'] = df['max_cycles'] - df['cycles']

    # Drop the intermediate 'max_cycles' column if desired
    df = df.drop(columns=['max_cycles'])

    return df

S6_RUL = add_RUL_column(modified_train.copy())
RUL = add_RUL_column(modified_train_No_S6.copy())

S6_RUL.head()

RUL.head()

S6_Outliers_RUL = add_RUL_column(train_No_S6_Outliers95.copy())
Outliers_RUL = add_RUL_column(train_Outliers95.copy())

S6_Outliers_RUL.head()

Outliers_RUL.head()

"""#Modelamiento"""

# Importo librerías necesarias
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error
from sklearn.dummy import DummyRegressor

"""Defino la función para evaluar los datos pre-procesados, es importante que se tiene en cuenta cuatro conjuntos de datos.

*   S6_RUL
*   RUL

Datos pre-procesados sin outliers

*   S6_Outliers_RUL
*   Outliers_RUL

Esta función muestra RMSE del modelo XGB, el RMSE del modelo XGB con predicción de salida de valor constante (media) y Feature Importance




"""

def train_evaluate_xgb_model(df):
    # Split the data into training and testing sets
    train_data = df[df['unit_number'] > 20]
    test_data = df[df['unit_number'] <= 20]

    # Seleccionar variables dependientes e independientes
    excluded_columns = ['unit_number', 'cycles', 'operational_settings_1', 'operational_settings_2', 'operational_settings_3', 'RUL']
    X_train = train_data.drop(columns=excluded_columns)
    y_train = train_data['RUL']

    X_test = test_data.drop(columns=excluded_columns)
    y_test = test_data['RUL']

    # Entrenar modelo (XGBoost Regressor model)
    model = XGBRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Evaluate the model on the test set
    y_pred = model.predict(X_test)
    rmse_model = mean_squared_error(y_test, y_pred, squared=False)

    # Evaluar modelo (RMSE) y compararlo con baseline de valor constante (media)
    # Se le llamrá "DummyRegressor"
    baseline_model = DummyRegressor(strategy='mean')
    baseline_model.fit(X_train, y_train)
    y_baseline = baseline_model.predict(X_test)
    rmse_baseline = mean_squared_error(y_test, y_baseline, squared=False)

    # Print and compare the RMSE values
    print(f"RMSE of the XGBoost model: {rmse_model}")
    print(f"RMSE of the baseline (mean): {rmse_baseline}")
    print(f"Improvement over baseline: {rmse_baseline - rmse_model}")

    # Graficar Feature Importance Plot
    feature_importances = model.feature_importances_
    features = X_train.columns
    sorted_idx = feature_importances.argsort()

    plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx])
    plt.yticks(range(len(sorted_idx)), features[sorted_idx])
    plt.xlabel('Feature Importance')
    plt.title('XGBoost Feature Importance')
    plt.show()

# Entrenamiento del conjunto de datos: S6_RUL
train_evaluate_xgb_model(S6_RUL)

# Entrenamiento del conjunto de datos: RUL
train_evaluate_xgb_model(RUL)

# Entrenamiento del conjunto de datos: S6_Outliers_RUL
train_evaluate_xgb_model(S6_Outliers_RUL)

# Entrenamiento del conjunto de datos: Outliers_RUL
train_evaluate_xgb_model(Outliers_RUL)

"""Como se puede observar, no existe mucha diferencia entre los 4 conjuntos de datos. Con valores RMSE cercanos a al rango [38,40]"""

pip install optuna

"""Se realiza la optimización de hiperparámetros para un modelo de regresión utilizando la biblioteca Optuna. Primero, se define la función objective que toma hiperparámetros como argumentos, crea un modelo XGBoost con esos hiperparámetros, lo entrena en el conjunto de entrenamiento y evalúa su RMSE.

Se utilizan hiperparámetros como el número de estimadores (n_estimators), la tasa de aprendizaje (learning_rate), y la profundidad máxima del árbol (max_depth)
"""

import optuna

def objective(trial, X_train, y_train, X_test, y_test):
    # Definir los hiperparámetros a optimizar
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 150),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),
        'max_depth': trial.suggest_int('max_depth', 3, 7),
        'random_state': 42
    }

    # Crear el modelo con los hiperparámetros propuestos
    model = XGBRegressor(**params)

    # Entrenar el modelo
    model.fit(X_train, y_train)

    # Predecir en el conjunto de prueba
    y_pred = model.predict(X_test)

    # Calcular el RMSE
    rmse = mean_squared_error(y_test, y_pred, squared=False)

    return rmse

def train_evaluate_xgb_model_optuna(df):
    # Split the data into training and testing sets
    train_data = df[df['unit_number'] > 20]
    test_data = df[df['unit_number'] <= 20]

    # Seleccionar variables dependientes e independientes
    excluded_columns = ['unit_number', 'cycles', 'operational_settings_1', 'operational_settings_2', 'operational_settings_3', 'RUL']
    X_train = train_data.drop(columns=excluded_columns)
    y_train = train_data['RUL']

    X_test = test_data.drop(columns=excluded_columns)
    y_test = test_data['RUL']

    # Definir la función objetivo para Optuna
    objective_func = lambda trial: objective(trial, X_train, y_train, X_test, y_test)

    # Crear un estudio de Optuna
    study = optuna.create_study(direction='minimize')

    # Ejecutar la optimización de hiperparámetros
    study.optimize(objective_func, n_trials=50)

    # Obtener los mejores hiperparámetros
    best_params = study.best_params
    print("Mejores hiperparámetros:", best_params)

    # Obtener el mejor modelo
    best_model = XGBRegressor(**best_params)
    best_model.fit(X_train, y_train)

    # Evaluar el modelo en el conjunto de prueba
    y_pred = best_model.predict(X_test)
    rmse_model = mean_squared_error(y_test, y_pred, squared=False)
    print(f"RMSE del mejor modelo en el conjunto de prueba: {rmse_model}")

    # Visualizar los resultados de Optuna
    optuna.visualization.plot_optimization_history(study)
    optuna.visualization.plot_param_importances(study)
    optuna.visualization.plot_contour(study, params=['n_estimators', 'learning_rate', 'max_depth'])
    plt.show()

"""#Optimización de Hiperparámetros

En este caso, se hará la optimización de los 4 modelos contemplados hasta ahora
"""

# Llamar a la función para la optimización con Optuna
train_evaluate_xgb_model_optuna(S6_RUL)

# Llamar a la función para la optimización con Optuna
train_evaluate_xgb_model_optuna(RUL)

# Llamar a la función para la optimización con Optuna
train_evaluate_xgb_model_optuna(S6_Outliers_RUL)

# Llamar a la función para la optimización con Optuna
train_evaluate_xgb_model_optuna(Outliers_RUL)

"""Ahora hemos optimizado el RMSE hasta valores cercanos al rango [35,36]. Hasta ahora y como hemos visto anteriormente, para estos cuatro conjuntos de datos. Se escogerá "S6_RUL" para entrenar al modelo con los parámetros optimizados y compararlo con el modelo obtenido con valores por defecto de ‘n_estimators’, ‘learning_rate’ y ‘max_depth’. Para ello se define una nueva función"""

def xgb_model_hyperparameters(df, n_estimators, learning_rate, max_depth):
    # Split the data into training and testing sets
    train_data = df[df['unit_number'] > 20]
    test_data = df[df['unit_number'] <= 20]

    # Seleccionar variables dependientes e independientes
    excluded_columns = ['unit_number', 'cycles', 'operational_settings_1', 'operational_settings_2', 'operational_settings_3', 'RUL']
    X_train = train_data.drop(columns=excluded_columns)
    y_train = train_data['RUL']

    X_test = test_data.drop(columns=excluded_columns)
    y_test = test_data['RUL']

    # Entrenar modelo (XGBoost Regressor model)
    model = XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)
    model.fit(X_train, y_train)

    # Evaluate the model on the test set
    y_pred = model.predict(X_test)
    rmse_model = mean_squared_error(y_test, y_pred, squared=False)

    # Print and compare the RMSE values
    print(f"RMSE of the XGBoost model: {rmse_model}")

    # Graficar Feature Importance Plot
    feature_importances = model.feature_importances_
    features = X_train.columns
    sorted_idx = feature_importances.argsort()

    plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx])
    plt.yticks(range(len(sorted_idx)), features[sorted_idx])
    plt.xlabel('Feature Importance')
    plt.title('XGBoost Feature Importance')
    plt.show()

# Llamada con valores especificados
specified_values = {'n_estimators': 115, 'learning_rate': 0.06514304345942185, 'max_depth': 3}
xgb_model_hyperparameters(S6_RUL, **specified_values)

"""Con esto, se tiene la comparación

*   RMSE con HyperParámetros default: 38.46
*   RMSE con HyperParámetros optimizados: 35.05

#Cross Validation
"""

def cross_validation_xgb_model(df, specified_values):
    # Extracting specified hyperparameters
    n_estimators = specified_values['n_estimators']
    learning_rate = specified_values['learning_rate']
    max_depth = specified_values['max_depth']

    # Extracting unique unit_numbers
    unit_numbers = df['unit_number'].unique()

    # Initialize KFold with 5 splits
    kfold = KFold(n_splits=5, shuffle=True, random_state=42)

    # List to store RMSE scores for each fold
    rmse_list = []

    # Loop through each fold
    for i, (train_idx, test_idx) in enumerate(kfold.split(unit_numbers)):
        # Extract training and testing unit_numbers for this fold
        train_unit_numbers = unit_numbers[train_idx]
        test_unit_numbers = unit_numbers[test_idx]

        # Split the data into training and testing sets
        train_data = df[df['unit_number'].isin(train_unit_numbers)]
        test_data = df[df['unit_number'].isin(test_unit_numbers)]

        # Select dependent and independent variables
        excluded_columns = ['unit_number', 'cycles', 'operational_settings_1', 'operational_settings_2', 'operational_settings_3', 'RUL']
        X_train = train_data.drop(columns=excluded_columns)
        y_train = train_data['RUL']

        X_test = test_data.drop(columns=excluded_columns)
        y_test = test_data['RUL']

        # Train model (XGBoost Regressor model)
        model = XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)
        model.fit(X_train, y_train)

        # Make predictions on test data
        y_pred = model.predict(X_test)

        # Calculate and store the RMSE score
        rmse = mean_squared_error(y_test, y_pred, squared=False)
        rmse_list.append({'Fold': i+1, 'RMSE': rmse})

    # Create a DataFrame from the list of RMSE scores
    rmse_df = pd.DataFrame(rmse_list)

    # Calculate and print the average RMSE across all folds
    average_rmse = np.mean(rmse_df['RMSE'])
    print("\nAverage RMSE across all folds:", average_rmse)

    # Print a table with all the RMSE scores
    print("\nRMSE for each fold:")
    print(rmse_df)

# Llamar a la función de validación cruzada
cross_validation_xgb_model(S6_RUL, specified_values)

"""#Adicional

Ahora, se puede ver como los hyperparámetros optimizados funciona solamente para cuando se tiene el caso donde Test Data ocurre cuando ['unit_number'] <= 20.

Por ello se ha generado un nuevo códogp que realiza la optimización de hiperparámetros para un modelo XGBoostRegressor mediante la combinación de validación cruzada K-Fold y GridSearchCV.

Se asume que el DataFrame de entrada, denotado como your_dataframe, contiene el conjunto de datos con características, variable objetivo y información adicional relacionada con las unidades. El código divide los datos en conjuntos de entrenamiento y prueba utilizando una estrategia K-Fold con cinco pliegues. Dentro de cada pliegue, realiza una búsqueda en cuadrícula sobre un espacio de hiperparámetros predefinido, que incluye diferentes valores para el número de árboles (n_estimators), tasa de aprendizaje (learning_rate), y la profundidad máxima de los árboles (max_depth).

El objetivo es encontrar la combinación óptima de hiperparámetros que minimice el error cuadrático medio raíz (RMSE) promedio en todos los pliegues. La salida es el RMSE promedio en todos los pliegues, proporcionando una evaluación del rendimiento del modelo con los hiperparámetros optimizados.
"""

import optuna
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
import numpy as np

def objective(trial, df, kf):
    # Select dependent and independent variables
    excluded_columns = ['unit_number', 'cycles', 'operational_settings_1', 'operational_settings_2', 'operational_settings_3', 'RUL']
    X = df.drop(columns=excluded_columns)
    y = df['RUL']

    rmse_list = []

    # Loop through each fold
    for i, (train_idx, test_idx) in enumerate(kf.split(X)):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        # Define the hyperparameters to optimize
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 50, 150),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),
            'max_depth': trial.suggest_int('max_depth', 3, 7),
            'random_state': 42
        }

        model = XGBRegressor(**params)
        model.fit(X_train, y_train)

        y_pred = model.predict(X_test)

        rmse_fold = mean_squared_error(y_test, y_pred, squared=False)
        rmse_list.append(rmse_fold)

    avg_rmse = np.mean(rmse_list)

    # Print fold-wise RMSE outside the loop
    for i, rmse_fold in enumerate(rmse_list):
        print(f"  RMSE K-Fold {i + 1}: {rmse_fold}")

    print(f"  RMSE Promedio: {avg_rmse}")

    return avg_rmse

def train_evaluate_xgb_model_optuna_kf(df, num_trials=50):
    # Define the objective function for Optuna
    kf = KFold(n_splits=5, shuffle=True, random_state=42)

    objective_func = lambda trial: objective(trial, df, kf)

    # Create an Optuna study
    study = optuna.create_study(direction='minimize')

    # Execute the hyperparameter optimization
    study.optimize(objective_func, n_trials=num_trials)

    # Get the best hyperparameters
    best_params = study.best_params
    # print("\nBest Hyperparameters:", best_params)

    # Visualize the results of Optuna
    optuna.visualization.plot_optimization_history(study)
    optuna.visualization.plot_param_importances(study)
    optuna.visualization.plot_contour(study, params=['n_estimators', 'learning_rate', 'max_depth'])
    plt.show()

    # Find the trial with the lowest average RMSE
    lowest_rmse_trial = min(study.trials, key=lambda trial: trial.value)

    # Print information about the trial with the lowest average RMSE
    print("\nTrial with Lowest Average RMSE:")
    print(f"Trial number: {lowest_rmse_trial.number + 1}")
    print(f"\nBest Hyperparameters: {lowest_rmse_trial.params}")
    print(f"Lowest Average RMSE: {lowest_rmse_trial.value}")

    # Print the 5 K-fold RMSE values for the trial with the lowest average RMSE
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    X = df.drop(columns=['unit_number', 'cycles', 'operational_settings_1', 'operational_settings_2', 'operational_settings_3', 'RUL'])
    y = df['RUL']

    for i, (train_idx, test_idx) in enumerate(kf.split(X)):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        params = lowest_rmse_trial.params
        model = XGBRegressor(**params)
        model.fit(X_train, y_train)

        y_pred = model.predict(X_test)

        rmse_fold = mean_squared_error(y_test, y_pred, squared=False)
        print(f"  RMSE K-Fold {i + 1}: {rmse_fold}")

# Example usage
train_evaluate_xgb_model_optuna_kf(S6_RUL, num_trials=50)

"""#Conclusiones

Se ha implementado un código parametrizable, el cual si se tuviera mucho más tiempo, se puede conseguir un RMSE en CONJUNTO, mucho menor. En el caso anterior, los hyperparámetros sirvieron para un solo caso, este nuevo código tiene un mayor costo computacional, el cual puede garantizar mejores resultados en conjuntos

Finalmente, se ha completado un análisis exhaustivo de los datos para el estimador de vida útil restante de motores de avión. Este proceso incluyó un análisis exploratorio de datos para eliminar información no relevante para el modelo. Se llevó a cabo una partición de los datos en conjuntos de entrenamiento y prueba, seguido de la optimización de hiperparámetros utilizando el modelo de regresión XGBoost. Como paso final, se aplicó una validación cruzada para garantizar una mayor robustez en el rendimiento del modelo.

#Armando Arturo Custodio Díaz
"""